{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cucqa7ue1BVH",
    "outputId": "b83b39f8-48b8-4d6b-997d-0f69894f2470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Install necessary packages\n",
    "!pip install pandas\n",
    "\n",
    "# CSV data sources:\n",
    "# https://www.kaggle.com/datasets/nelgiriyewithana/countries-of-the-world-2023 - download the world-data-2023.csv\n",
    "# https://www.kaggle.com/datasets/myrios/cost-of-living-index-by-country-by-number-2024 - download the Cost_of_Living_Index_by_Country_2024.csv\n",
    "# Upload them to your Google Colab environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'merged_dataset.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1_path = 'DATA/Cost_of_Living_Index_by_Country_2024.csv'\n",
    "file2_path = 'DATA/world-data-2023.csv'\n",
    "\n",
    "df1 = pd.read_csv(file1_path)\n",
    "df2 = pd.read_csv(file2_path)\n",
    "\n",
    "df1_head = df1.head()\n",
    "df2_head = df2.head()\n",
    "\n",
    "df1_columns = df1.columns\n",
    "df2_columns = df2.columns\n",
    "\n",
    "df1_head, df2_head, df1_columns, df2_columns\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on='Country', how='inner')\n",
    "\n",
    "merged_df_shape = merged_df.shape\n",
    "merged_df_head = merged_df.head()\n",
    "\n",
    "merged_df_shape, merged_df_head\n",
    "\n",
    "output_path = 'merged_dataset.csv'\n",
    "merged_df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmkE9nXz1r_q",
    "outputId": "b09707ad-28c6-47f6-be9f-d6aaff1a25a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/hanyan/DS-2002-Final-Project\n",
      "Files in the current directory: ['DS_2002_Final_Project_ETL_setup.ipynb', '.git', '.venv', 'README.md']\n"
     ]
    }
   ],
   "source": [
    "# Check working directory to see if the files were uploaded correctly\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in the current directory:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UkQYg98pwEXY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:68: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:68: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_4115/410432596.py:68: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  df['Birth Rate'] = pd.to_numeric(df['Birth Rate'].astype(str).str.replace('[^\\d.]', '', regex=True), errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "def fetch_data(file_path):\n",
    "    \"\"\"\n",
    "    Fetch data from a CSV file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: The file {file_path} does not exist.\")\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully read CSV file from {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while reading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_format(df, output_format):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to specified output format\n",
    "    \"\"\"\n",
    "    if output_format == 'json':\n",
    "        return df.to_json(orient='records')\n",
    "    elif output_format == 'csv':\n",
    "        return df.to_csv(index=False)\n",
    "    elif output_format == 'sql':\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"Invalid output format. Choose 'json', 'csv', or 'sql'.\")\n",
    "\n",
    "def modify_columns(df, columns_to_keep=None, columns_to_add=None):\n",
    "    \"\"\"\n",
    "    Modify DataFrame columns based on user input\n",
    "    \"\"\"\n",
    "    if columns_to_keep:\n",
    "        df = df[columns_to_keep]\n",
    "    if columns_to_add:\n",
    "        df = df.assign(**columns_to_add)\n",
    "    return df\n",
    "\n",
    "def store_data(data, output_format, filename=None, table_name=None):\n",
    "    \"\"\"\n",
    "    Store data in specified format (file or SQL database)\n",
    "    \"\"\"\n",
    "    if output_format in ['json', 'csv']:\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(data)\n",
    "        print(f\"Data stored in {filename}\")\n",
    "    elif output_format == 'sql':\n",
    "        with sqlite3.connect('output.db') as conn:\n",
    "            data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "        print(f\"Data stored in SQLite database 'output.db', table '{table_name}'\")\n",
    "\n",
    "def generate_summary(df, stage):\n",
    "    \"\"\"\n",
    "    Generate and print summary of the data\n",
    "    \"\"\"\n",
    "    print(f\"\\n{stage} Summary:\")\n",
    "    print(f\"Number of records: {len(df)}\")\n",
    "    print(f\"Number of columns: {len(df.columns)}\")\n",
    "    print(f\"Columns: {', '.join(df.columns)}\")\n",
    "\n",
    "def clean_birth_rate_data(df):\n",
    "    \"\"\"\n",
    "    Clean and transform birth rate data\n",
    "    \"\"\"\n",
    "    columns_to_keep = ['Country', 'Birth Rate']\n",
    "    df = df[columns_to_keep]\n",
    "    df = df.dropna()\n",
    "    df['Birth Rate'] = pd.to_numeric(df['Birth Rate'].astype(str).str.replace('[^\\d.]', '', regex=True), errors='coerce')\n",
    "    return df\n",
    "\n",
    "def clean_cost_of_living_data(df):\n",
    "    \"\"\"\n",
    "    Clean and transform cost of living data\n",
    "    \"\"\"\n",
    "    columns_to_keep = ['Country', 'Cost of Living Index']\n",
    "    df = df[columns_to_keep]\n",
    "    df = df.dropna()\n",
    "    df['Cost of Living Index'] = pd.to_numeric(df['Cost of Living Index'], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SVNvLlTTwE-I"
   },
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Get user input for data source and output format\n",
    "    \"\"\"\n",
    "    output_format = input(\"Enter output format (json/csv/sql): \").lower()\n",
    "    return output_format\n",
    "\n",
    "def get_column_modifications():\n",
    "    \"\"\"\n",
    "    Get user input for column modifications\n",
    "    \"\"\"\n",
    "    columns_to_keep = input(\"Enter columns to keep (comma-separated, leave blank for all): \").split(',') if input(\"Do you want to keep specific columns? (y/n): \").lower() == 'y' else None\n",
    "    columns_to_add = {col: input(f\"Enter value for new column '{col}': \") for col in input(\"Enter new columns to add (comma-separated, leave blank for none): \").split(',') if col}\n",
    "    return columns_to_keep, columns_to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQX65L-gwI1D",
    "outputId": "d4b772e8-cc1c-4e39-bc10-7f6ace73969e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file /content/world-data-2023.csv does not exist.\n",
      "Error: The file /content/Cost_of_Living_Index_by_Country_2024.csv does not exist.\n",
      "An error occurred: Failed to fetch data\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the ETL pipeline\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch data\n",
    "        birth_rate_df = fetch_data(\"/content/world-data-2023.csv\")\n",
    "        cost_of_living_df = fetch_data(\"/content/Cost_of_Living_Index_by_Country_2024.csv\")\n",
    "\n",
    "        if birth_rate_df is None or cost_of_living_df is None:\n",
    "            raise ValueError(\"Failed to fetch data\")\n",
    "\n",
    "        # Generate pre-processing summary\n",
    "        generate_summary(birth_rate_df, \"Birth Rate Pre-processing\")\n",
    "        generate_summary(cost_of_living_df, \"Cost of Living Pre-processing\")\n",
    "\n",
    "        # Clean and transform data\n",
    "        cleaned_birth_rate_df = clean_birth_rate_data(birth_rate_df)\n",
    "        cleaned_cost_of_living_df = clean_cost_of_living_data(cost_of_living_df)\n",
    "\n",
    "        # Merge datasets\n",
    "        merged_df = pd.merge(cleaned_birth_rate_df, cleaned_cost_of_living_df, on='Country', how='inner')\n",
    "\n",
    "        # Get user input\n",
    "        output_format = get_user_input()\n",
    "\n",
    "        # Modify columns\n",
    "        columns_to_keep, columns_to_add = get_column_modifications()\n",
    "        merged_df = modify_columns(merged_df, columns_to_keep, columns_to_add)\n",
    "\n",
    "        # Convert format\n",
    "        converted_data = convert_format(merged_df, output_format)\n",
    "\n",
    "        # Store data\n",
    "        if output_format in ['json', 'csv']:\n",
    "            filename = f\"/content/{input('Enter output filename: ')}\"\n",
    "            store_data(converted_data, output_format, filename)\n",
    "        elif output_format == 'sql':\n",
    "            table_name = input(\"Enter SQL table name: \")\n",
    "            store_data(merged_df, output_format, table_name=table_name)\n",
    "\n",
    "        # Generate post-processing summary\n",
    "        generate_summary(merged_df, \"Post-processing\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
